!pip install numpy seaborn tqdm


import polars as pl
import hashlib
import random 
import numpy as np
from steganodf.algorithms import BitPool
from reedsolo import RSCodec
import seaborn as sns
import statistics
import matplotlib.pyplot as plt
import string
from tqdm import tqdm
import concurrent.futures
%load_ext autoreload
%autoreload 2








df = pl.read_csv("heart_attack_predictions.csv")
df





def estimate(algo, df):
    """ 
    estime la capacitÃ© max d'un df
    """
    max_size = []
    mmax = 0    
    index = 1
    while True:
        i = index % len(string.ascii_letters)
        payload = string.ascii_letters[:index]
        payload = payload.encode()
        encoded_df = algo.encode(df, payload)

        if algo.decode(encoded_df) == payload:
            mmax = index
            index+=1
        else:
            break

    return mmax



results = []

for b in [5,10]:
    for s in tqdm(range(0, 2000, 500)):
        a = BitPool(bit_per_row=1, parity_size=0, block_size=b)
        sdf = df.head(s)
        ss = []
        for i in range(4):
            size = estimate(a, sdf)
            results.append({"total": s, "payload": size, "bloc_size": b, "pmax": a.get_max_payload_size(sdf) })

        
df = pl.DataFrame(results)
df


ddf= pl.DataFrame(results)
#ddf = ddf.filter(pl.col("total") > 1000)

ddf = ddf.with_columns(pl.col("bloc_size").cast(pl.String()).alias("bloc"))

ax = sns.lineplot(x="total", y="payload", hue="bloc", marker="_", data=ddf)
#ax2 = sns.lineplot(x="total", y="pmax", hue="bloc", c="gray", marker="", data=ddf)

plt.xlabel("row count", fontsize=12)
plt.ylabel("payload (bytes)", fontsize=12)
plt.legend(title="block size (bytes)")
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.title("Data Embedding size as a Function of Row Count")






with open("lena.png","rb") as file:
    data = file.read()

len(data)





def find_max_crop_size(algo, df, data):
    """ dichomie """

    left = 0
    right = len(df)
    while left < right:
        middle = (left + right) // 2
        stego_data = algo.decode(df[:middle])
        if stego_data != data:
            left = middle + 1
        else:
            right = middle

    return left if left <= len(df) else -1 


find_max_crop_size(a, stego_df, data)


results = []

blocks = (5, 1000)
datas = [generate_payload(x) for x in (100, 500, 1000)]

for b in blocks:
    for data in datas:
        a = BitPool(bit_per_row=1, parity_size=0, block_size=b)
        stego_df = a.encode(df, data)
        croping_size = find_max_crop_size(a, stego_df, data)
    
        results.append(
            {
                "block": b, 
                "data": len(data),
                "cropping_size": croping_size
            }
        )

croping_size






rdf  = pl.DataFrame(results)
rdf

sns.barplot(x="block", y="cropping_size", hue="data", data=rdf)


stego_data = a.decode(stego_df[:2577])
stego_data == data


from PIL import Image
from io import BytesIO
from IPython.display import display


a = BitPool(bit_per_row=2, block_size=5, parity_size=5)
sdf, count = a._encode(df, data)

print(count)


a.get_packet_size() * 2714 * 8


import matplotlib.pyplot as plt
import altair as alt


6 * len(df) / 100


len(df) / 37381





mdf = sdf.clone()

percent = 4
count = int(len(mdf) * (percent / 100))
index = random.sample(range(len(mdf)), count)

fdf = mdf.with_row_index().filter(~pl.col("index").is_in(index)).drop("index")

data2= a._decode(fdf)

image_data = BytesIO(data2["payload"])
# Ouvrir l'image avec Pillow
image = Image.open(image_data)
# Afficher l'image
display(image)


5 * len(mdf) / 100


len(mdf) / 31151


a.get_packet_size()


20/8


a.get_packet_size()


df = ddf.filter(pl.col("bloc_size") == "5")

X = df["total"][50:].to_numpy().reshape(-1,1)
y = df["payload"][50:].to_numpy()


model = LinearRegression()
model.fit(X,y)

model.score(X,y)

a = model.coef_[0]
b = model.intercept_

print(a,b)






1000*0.01


df.filter(pl.col("total") == 1700)


df_encoded = df.to_pandas()



def create_error(mdf, percent):
    
    df_encoded = mdf.to_pandas().copy()
 
    count = len(df_encoded) * percent // 100
    if count == 0:
        return mdf

    count = int(count)
    idx = random.sample(range(len(df_encoded)), k = count)
    df_encoded.iloc[idx, 0] = None
    return pl.from_pandas(df_encoded)




t = pl.DataFrame({"a": range(10), "b": range(10)})

create_error(t, 50.0)


def create_deletion(mdf, percent):
    df_encoded = mdf.to_pandas()
    size = len(df_encoded)
    count = int(percent * size / 100) 
    
    index = df_encoded.sample(count).index
    df_encoded = df_encoded.drop(index)

    return pl.from_pandas(df_encoded)


    

    


import numpy as np

np.arange(0, 2, 0.1)


df = pl.read_csv("heart_attack_predictions.csv")
df = df.head(10000)
payload = b"se"

results = []
for p in tqdm(range(1,30,1)):
    for b in [5, 25]:
        a = BitPool(bit_per_row=1, parity_size=p, block_size=b)
        sdf = a.encode(df, payload)
        max_error = 0.0
        error  = 0.0
        while True:
            sdf = create_error(sdf, error)
            if a.decode(sdf) == payload:
                max_error = error
                error += 0.1
            else:
                break
        
        results.append({"p": p, "b": b, "error": max_error})


results = pl.DataFrame(results)



gdf = pl.DataFrame(results)
gdf.write_parquet("error.parquet")


sns.lineplot(x="p", y="error", hue="b", marker="o", data = gdf.to_pandas())

plt.xlabel("Correction code length (bytes)", fontsize=12)
plt.ylabel("Max. supported error (%)", fontsize=12)
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.title("Row error tolerance based on correction code length")




df = pl.read_csv("heart_attack_predictions.csv")
df = df.head(5000)
payload = b'secret'
ntry = 5
results = []

for b in [5,25]:
    for parity in tqdm(range(1, 20, 5)):
    
        for _ in range(ntry):
            a = BitPool(bit_per_row=1, parity_size=parity, block_size=b)
            edf = a.encode(df,payload)

            for error in range(0, 100, 20):
                
                edf_error = create_error(edf, error)
                if a.decode(mdf) == payload:
                    max_error = error
                else:
                    break
        
            results.append(
                {
                    "parity": parity,
                    "error" : max_error,
                    "block": b
                }
            )






gdf = pl.DataFrame(results)
gdf.write_parquet("error.parquet")


sns.lineplot(x="parity", y="error", hue="block", data = gdf.to_pandas())

plt.xlabel("Correction code length (bytes)", fontsize=12)
plt.ylabel("Max. supported error (%)", fontsize=12)
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.title("Row error tolerance based on correction code length")






